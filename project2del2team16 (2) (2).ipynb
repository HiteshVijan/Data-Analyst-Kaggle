{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-18T04:19:13.529954Z","iopub.execute_input":"2023-04-18T04:19:13.530499Z","iopub.status.idle":"2023-04-18T04:19:13.563740Z","shell.execute_reply.started":"2023-04-18T04:19:13.530456Z","shell.execute_reply":"2023-04-18T04:19:13.562513Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/data-analyst-job-postings-google-search/gsearch_jobs.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install PyMySql","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:13.565496Z","iopub.execute_input":"2023-04-18T04:19:13.565853Z","iopub.status.idle":"2023-04-18T04:19:27.344955Z","shell.execute_reply.started":"2023-04-18T04:19:13.565819Z","shell.execute_reply":"2023-04-18T04:19:27.343615Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting PyMySql\n  Downloading PyMySQL-1.0.3-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyMySql\nSuccessfully installed PyMySql-1.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:27.346642Z","iopub.execute_input":"2023-04-18T04:19:27.346977Z","iopub.status.idle":"2023-04-18T04:19:27.357200Z","shell.execute_reply.started":"2023-04-18T04:19:27.346945Z","shell.execute_reply":"2023-04-18T04:19:27.356063Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/data-analyst-job-postings-google-search/gsearch_jobs.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:27.360811Z","iopub.execute_input":"2023-04-18T04:19:27.361520Z","iopub.status.idle":"2023-04-18T04:19:27.497673Z","shell.execute_reply.started":"2023-04-18T04:19:27.361478Z","shell.execute_reply":"2023-04-18T04:19:27.496141Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"69"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file into a Pandas dataframe\njobposting_df = pd.read_csv(\"/kaggle/input/data-analyst-job-postings-google-search/gsearch_jobs.csv\")\n\n# Display the first 5 rows of the dataframe\nprint(jobposting_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:27.499334Z","iopub.execute_input":"2023-04-18T04:19:27.499663Z","iopub.status.idle":"2023-04-18T04:19:29.552420Z","shell.execute_reply.started":"2023-04-18T04:19:27.499632Z","shell.execute_reply":"2023-04-18T04:19:29.551127Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"   Unnamed: 0  index                    title      company_name  \\\n0           0      0    Business Data Analyst      Aurora Solar   \n1           1      1      Senior Data Analyst     Tendo Systems   \n2           2      2  Data Analyst III-Remote         Corporate   \n3           3      3          Data Analyst II  Summit Utilities   \n4           4      4  Data Analyst III-Remote         Corporate   \n\n                  location                              via  \\\n0         United States                     via Ai-Jobs.net   \n1                Anywhere                  via Startup Jobs   \n2          Columbia, MO     via Central Illinois Proud Jobs   \n3        Fort Smith, AR                 via Relocation Jobs   \n4    Jefferson City, MO     via Central Illinois Proud Jobs   \n\n                                         description  \\\n0  About the role:Aurora Solar is a fast-growing ...   \n1  As a Senior Data Analyst, you will play a cruc...   \n2  You could be the one who changes everything fo...   \n3  Join our Growing Team and see why Summit Utili...   \n4  You could be the one who changes everything fo...   \n\n                                          extensions  \\\n0  ['17 hours ago', '87.5K–142K a year', 'Full-ti...   \n1  ['20 hours ago', 'Work from home', 'Full-time'...   \n2  ['21 hours ago', 'Full-time', 'Health insuranc...   \n3  ['16 hours ago', 'Full-time', 'Health insuranc...   \n4  ['21 hours ago', 'Full-time', 'Health insuranc...   \n\n                                              job_id thumbnail  ...  \\\n0  eyJqb2JfdGl0bGUiOiJCdXNpbmVzcyBEYXRhIEFuYWx5c3...       NaN  ...   \n1  eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0Ii...       NaN  ...   \n2  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgSUlJLVJlbW...       NaN  ...   \n3  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgSUkiLCJodG...       NaN  ...   \n4  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgSUlJLVJlbW...       NaN  ...   \n\n  commute_time  salary_pay salary_rate salary_avg salary_min salary_max  \\\n0          NaN  87.5K–142K      a year   114750.0    87500.0   142000.0   \n1          NaN         NaN         NaN        NaN        NaN        NaN   \n2          NaN         NaN         NaN        NaN        NaN        NaN   \n3          NaN         NaN         NaN        NaN        NaN        NaN   \n4          NaN         NaN         NaN        NaN        NaN        NaN   \n\n  salary_hourly  salary_yearly salary_standardized  \\\n0           NaN       114750.0            114750.0   \n1           NaN            NaN                 NaN   \n2           NaN            NaN                 NaN   \n3           NaN            NaN                 NaN   \n4           NaN            NaN                 NaN   \n\n                                  description_tokens  \n0  ['python', 'looker', 'snowflake', 'sql', 'auro...  \n1                                 ['sql', 'jupyter']  \n2                            ['sql', 'sap', 'excel']  \n3  ['sap', 'azure', 'sql', 'excel', 'power_bi', '...  \n4                            ['sql', 'sap', 'excel']  \n\n[5 rows x 27 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Info about job posting table\njobposting_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:29.553707Z","iopub.execute_input":"2023-04-18T04:19:29.554022Z","iopub.status.idle":"2023-04-18T04:19:29.595819Z","shell.execute_reply.started":"2023-04-18T04:19:29.553989Z","shell.execute_reply":"2023-04-18T04:19:29.594415Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 15964 entries, 0 to 15963\nData columns (total 27 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Unnamed: 0           15964 non-null  int64  \n 1   index                15964 non-null  int64  \n 2   title                15964 non-null  object \n 3   company_name         15964 non-null  object \n 4   location             15950 non-null  object \n 5   via                  15964 non-null  object \n 6   description          15964 non-null  object \n 7   extensions           15964 non-null  object \n 8   job_id               15964 non-null  object \n 9   thumbnail            8565 non-null   object \n 10  posted_at            15964 non-null  object \n 11  schedule_type        15862 non-null  object \n 12  work_from_home       7229 non-null   object \n 13  salary               3057 non-null   object \n 14  search_term          15964 non-null  object \n 15  date_time            15964 non-null  object \n 16  search_location      15964 non-null  object \n 17  commute_time         0 non-null      float64\n 18  salary_pay           3057 non-null   object \n 19  salary_rate          3057 non-null   object \n 20  salary_avg           3057 non-null   float64\n 21  salary_min           2870 non-null   float64\n 22  salary_max           2870 non-null   float64\n 23  salary_hourly        1735 non-null   float64\n 24  salary_yearly        1316 non-null   float64\n 25  salary_standardized  3057 non-null   float64\n 26  description_tokens   15964 non-null  object \ndtypes: float64(7), int64(2), object(18)\nmemory usage: 3.3+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from sqlalchemy import create_engine\n\n!pip install PyMySql\n\nimport pymysql\n\nimport sqlalchemy\n\nimport sqlite3","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:29.597724Z","iopub.execute_input":"2023-04-18T04:19:29.598083Z","iopub.status.idle":"2023-04-18T04:19:41.023883Z","shell.execute_reply.started":"2023-04-18T04:19:29.598045Z","shell.execute_reply":"2023-04-18T04:19:41.022534Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyMySql in /opt/conda/lib/python3.7/site-packages (1.0.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# creating an engine\n\nengine = create_engine('sqlite:////kaggle/working/Prabs1.db')","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:41.025673Z","iopub.execute_input":"2023-04-18T04:19:41.026028Z","iopub.status.idle":"2023-04-18T04:19:41.067579Z","shell.execute_reply.started":"2023-04-18T04:19:41.025993Z","shell.execute_reply":"2023-04-18T04:19:41.066604Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Using the engine, we are porting jobposting table by writing records stored in DataFrames\njobposting_df.to_sql(name = \"Job_Posting\", con = engine, if_exists='replace', index=True, chunksize=10000)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:41.069020Z","iopub.execute_input":"2023-04-18T04:19:41.069945Z","iopub.status.idle":"2023-04-18T04:19:42.785092Z","shell.execute_reply.started":"2023-04-18T04:19:41.069899Z","shell.execute_reply":"2023-04-18T04:19:42.783805Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%sql sqlite:////kaggle/working/Prabs.db","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:42.788915Z","iopub.execute_input":"2023-04-18T04:19:42.789346Z","iopub.status.idle":"2023-04-18T04:19:42.796667Z","shell.execute_reply.started":"2023-04-18T04:19:42.789309Z","shell.execute_reply":"2023-04-18T04:19:42.795517Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import pymysql\n\nimport sqlalchemy\n\nimport sqlite3","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:42.798331Z","iopub.execute_input":"2023-04-18T04:19:42.798698Z","iopub.status.idle":"2023-04-18T04:19:42.807550Z","shell.execute_reply.started":"2023-04-18T04:19:42.798663Z","shell.execute_reply":"2023-04-18T04:19:42.806375Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%sql sqlite:////kaggle/working/Prabs1.db","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:42.809041Z","iopub.execute_input":"2023-04-18T04:19:42.809400Z","iopub.status.idle":"2023-04-18T04:19:42.820037Z","shell.execute_reply.started":"2023-04-18T04:19:42.809367Z","shell.execute_reply":"2023-04-18T04:19:42.818806Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"1. How many job postings require a Master's degree or higher?","metadata":{}},{"cell_type":"code","source":"%%sql\nSELECT COUNT(*) AS master_required_count\nFROM Job_Posting\nWHERE description LIKE '%master%' OR description LIKE '%phd%' OR description LIKE '%doctoral%'\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:19:42.821474Z","iopub.execute_input":"2023-04-18T04:19:42.822256Z","iopub.status.idle":"2023-04-18T04:19:43.016184Z","shell.execute_reply.started":"2023-04-18T04:19:42.822188Z","shell.execute_reply":"2023-04-18T04:19:43.014687Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"   sqlite:////kaggle/working/Prabs.db\n * sqlite:////kaggle/working/Prabs1.db\nDone.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[(3157,)]","text/html":"<table>\n    <tr>\n        <th>master_required_count</th>\n    </tr>\n    <tr>\n        <td>3157</td>\n    </tr>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"2. How many job postings are work-from-home and what is the average salary range for these postings?","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%sql\nSELECT \n    (SELECT COUNT(*) \n     FROM Job_Posting \n     WHERE work_from_home = '1') AS work_from_home_count, \n    round(AVG(salary_avg), 2) AS avg_salary\nFROM Job_Posting \nWHERE work_from_home = '1'\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:34:25.225044Z","iopub.execute_input":"2023-04-18T04:34:25.225462Z","iopub.status.idle":"2023-04-18T04:34:25.290737Z","shell.execute_reply.started":"2023-04-18T04:34:25.225425Z","shell.execute_reply":"2023-04-18T04:34:25.289712Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"   sqlite:////kaggle/working/Prabs.db\n * sqlite:////kaggle/working/Prabs1.db\nDone.\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[(7229, 22389.55)]","text/html":"<table>\n    <tr>\n        <th>work_from_home_count</th>\n        <th>avg_salary</th>\n    </tr>\n    <tr>\n        <td>7229</td>\n        <td>22389.55</td>\n    </tr>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"3. What is the average salary range for data analyst job postings in the top 5 locations with the highest number of job postings?","metadata":{}},{"cell_type":"code","source":"%%sql\nWITH location_cte AS (\n    SELECT location, COUNT(*) AS posting_count\n    FROM Job_Posting\n    GROUP BY location\n    ORDER BY posting_count DESC\n    LIMIT 5\n)\nSELECT \n    location_cte.location, \n    round(AVG(salary_avg),2) AS avg_salary\nFROM Job_Posting\nJOIN location_cte ON Job_Posting.location = location_cte.location\nWHERE salary_avg IS NOT NULL\nGROUP BY location_cte.location\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:33:14.844448Z","iopub.execute_input":"2023-04-18T04:33:14.844874Z","iopub.status.idle":"2023-04-18T04:33:15.032134Z","shell.execute_reply.started":"2023-04-18T04:33:14.844837Z","shell.execute_reply":"2023-04-18T04:33:15.031055Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"   sqlite:////kaggle/working/Prabs.db\n * sqlite:////kaggle/working/Prabs1.db\nDone.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[('Anywhere', 22288.62),\n ('Jefferson City, MO', 89310.77),\n ('Kansas City, MO', 57692.56),\n ('Oklahoma City, OK', 76828.01),\n ('United States', 64285.83)]","text/html":"<table>\n    <tr>\n        <th>location</th>\n        <th>avg_salary</th>\n    </tr>\n    <tr>\n        <td>Anywhere</td>\n        <td>22288.62</td>\n    </tr>\n    <tr>\n        <td>Jefferson City, MO</td>\n        <td>89310.77</td>\n    </tr>\n    <tr>\n        <td>Kansas City, MO</td>\n        <td>57692.56</td>\n    </tr>\n    <tr>\n        <td>Oklahoma City, OK</td>\n        <td>76828.01</td>\n    </tr>\n    <tr>\n        <td>United States</td>\n        <td>64285.83</td>\n    </tr>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"4. How many job postings have a salary range above the national average for data analyst positions?","metadata":{}},{"cell_type":"code","source":"%%sql\nWITH national_avg_cte AS (\n    SELECT AVG(salary_avg) AS national_avg\n    FROM Job_Posting\n    WHERE salary_avg IS NOT NULL\n)\nSELECT COUNT(*) AS high_salary_count\nFROM Job_Posting\nWHERE salary_avg > (\n    SELECT national_avg FROM national_avg_cte\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:35:06.543411Z","iopub.execute_input":"2023-04-18T04:35:06.543809Z","iopub.status.idle":"2023-04-18T04:35:06.611317Z","shell.execute_reply.started":"2023-04-18T04:35:06.543775Z","shell.execute_reply":"2023-04-18T04:35:06.610204Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"   sqlite:////kaggle/working/Prabs.db\n * sqlite:////kaggle/working/Prabs1.db\nDone.\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[(1308,)]","text/html":"<table>\n    <tr>\n        <th>high_salary_count</th>\n    </tr>\n    <tr>\n        <td>1308</td>\n    </tr>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"5. How many job postings require SQL or Python, and what is the average salary range for each skill?","metadata":{}},{"cell_type":"code","source":"%%sql\nWITH skill_counts AS (\n  SELECT \n    SUM(CASE WHEN LOWER(description) LIKE '%sql%' THEN 1 ELSE 0 END) AS sql_count,\n    SUM(CASE WHEN LOWER(description) LIKE '%python%' THEN 1 ELSE 0 END) AS python_count\n  FROM Job_Posting\n),\nsql_stats AS (\n  SELECT \n    COUNT(*) AS job_count,\n    ROUND(AVG(salary_standardized),2) AS avg_salary,\n    MIN(salary_standardized) AS min_salary,\n    MAX(salary_standardized) AS max_salary\n  FROM Job_Posting\n  WHERE LOWER(description) LIKE '%sql%' AND salary_standardized IS NOT NULL\n),\npython_stats AS (\n  SELECT \n    COUNT(*) AS job_count,\n    ROUND(AVG(salary_standardized),2) AS avg_salary,\n    MIN(salary_standardized) AS min_salary,\n    MAX(salary_standardized) AS max_salary\n  FROM Job_Posting\n  WHERE LOWER(description) LIKE '%python%' AND salary_standardized IS NOT NULL\n)\nSELECT \n  skill_counts.sql_count, \n  sql_stats.job_count AS sql_job_count, \n  sql_stats.avg_salary AS sql_avg_salary, \n  sql_stats.min_salary AS sql_min_salary, \n  sql_stats.max_salary AS sql_max_salary,\n  skill_counts.python_count, \n  python_stats.job_count AS python_job_count, \n  python_stats.avg_salary AS python_avg_salary, \n  python_stats.min_salary AS python_min_salary, \n  python_stats.max_salary AS python_max_salary\nFROM skill_counts\nCROSS JOIN sql_stats\nCROSS JOIN python_stats;\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:24:33.158044Z","iopub.execute_input":"2023-04-18T04:24:33.158476Z","iopub.status.idle":"2023-04-18T04:24:33.776739Z","shell.execute_reply.started":"2023-04-18T04:24:33.158431Z","shell.execute_reply":"2023-04-18T04:24:33.775754Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"   sqlite:////kaggle/working/Prabs.db\n * sqlite:////kaggle/working/Prabs1.db\nDone.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[(8832, 1491, 101117.97, 18720.0, 260000.0, 4668, 632, 103242.08, 18720.0, 322400.0)]","text/html":"<table>\n    <tr>\n        <th>sql_count</th>\n        <th>sql_job_count</th>\n        <th>sql_avg_salary</th>\n        <th>sql_min_salary</th>\n        <th>sql_max_salary</th>\n        <th>python_count</th>\n        <th>python_job_count</th>\n        <th>python_avg_salary</th>\n        <th>python_min_salary</th>\n        <th>python_max_salary</th>\n    </tr>\n    <tr>\n        <td>8832</td>\n        <td>1491</td>\n        <td>101117.97</td>\n        <td>18720.0</td>\n        <td>260000.0</td>\n        <td>4668</td>\n        <td>632</td>\n        <td>103242.08</td>\n        <td>18720.0</td>\n        <td>322400.0</td>\n    </tr>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"6. How many job postings have a salary above $100,000, and what is the average salary for those postings?","metadata":{}},{"cell_type":"code","source":"%%sql\nWITH high_salary_jobs AS (\n  SELECT * \n  FROM Job_Posting\n  WHERE salary_standardized IS NOT NULL AND salary_standardized > 100000\n    AND LOWER(title) LIKE '%analyst%'\n)\nSELECT COUNT(*) AS job_count, ROUND(AVG(salary_standardized),2) AS avg_salary\nFROM high_salary_jobs;\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T04:43:19.277150Z","iopub.execute_input":"2023-04-18T04:43:19.277574Z","iopub.status.idle":"2023-04-18T04:43:19.320054Z","shell.execute_reply.started":"2023-04-18T04:43:19.277536Z","shell.execute_reply":"2023-04-18T04:43:19.318860Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"   sqlite:////kaggle/working/Prabs.db\n * sqlite:////kaggle/working/Prabs1.db\nDone.\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[(830, 129899.33)]","text/html":"<table>\n    <tr>\n        <th>job_count</th>\n        <th>avg_salary</th>\n    </tr>\n    <tr>\n        <td>830</td>\n        <td>129899.33</td>\n    </tr>\n</table>"},"metadata":{}}]}]}